# SPDX-License-Identifier: Apache-2.0

click>=8.1.7,<9.0.0
click-didyoumean>=0.3.0
datasets>=2.18.0
gguf>=0.6.0
GitPython>=3.1.42
httpx>=0.25.0
instructlab-eval>=0.1.1
instructlab-quantize>=0.1.0
instructlab-schema>=0.4.0
instructlab-sdg>=0.3.0
instructlab-training>=0.4.1
llama_cpp_python[server]==0.2.79
mlx>=0.5.1,<0.6.0; sys_platform == 'darwin' and platform_machine == 'arm64'
numpy>=1.26.4,<2.0.0
openai>=1.13.3
peft>=0.9.0
prompt-toolkit>=3.0.38
pydantic>=2.7.4
pydantic_yaml>=1.2.0
PyYAML>=6.0.0
rich>=13.3.1
rouge-score>=0.1.2
ruamel.yaml>=0.17.0
sentencepiece>=0.2.0
# "old" version required for vLLM on CUDA to build
tokenizers>=0.11.1
toml>=0.10.2
# Habana Labs 1.17.1 has PyTorch 2.3.1a0+gitxxx pre-release
torch>=2.3.0,<2.4.0
tqdm>=4.66.2
# 'optimum' for Intel Gaudi needs transformers <4.44.0,>=4.43.0
transformers>=4.41.2
trl>=0.9.4
wandb>=0.16.4
xdg-base-dirs>=6.0.1
